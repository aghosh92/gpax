{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ziatdinovmax/gpax/blob/main/examples/gpax_GPBO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBXRVrQFPaK4"
   },
   "source": [
    "# Gaussian process-based Bayesian optimization\n",
    "\n",
    "*Prepared by Maxim Ziatdinov (2022). Last updated in October 2023.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMCrTM8HPfuX"
   },
   "source": [
    "As described in earlier examples, Gaussian process (GP) is a powerful tool for reconstructing an unknown function from sparse measurements in the probabilistic fashion. In addition to providing a \"one-off\" reconstruction, the GP's posterior predictive mean and uncertainty can be used to derive an acquisition function for selecting the next point to measure in the optimization problems. In the fully Bayesian regime, the next measurement point is selected according to\n",
    "\n",
    "$$ x_{next}= \\underset{x}{\\arg\\max}\\frac{1}{L}‚àë_{i=1}^LŒ±(ùúá_*^i,ùì•_*^i)\\qquad (1) $$\n",
    "\n",
    "where $L$ is the total number of Hamiltonian Monte Carlo samples,  $ùúá_*^i$ is a posterior predictive mean, and $ùì•_*^i$ is a posterior predictive variance for *i*-th sample. Perhaps the simplest acquisition function is an upper confidence bound (UCB) defined as\n",
    "\n",
    "$$ Œ±_{UCB}^i= ùúá_*^i\\pm\\sqrt{ùõΩ\\space ùì•_*^i}\\qquad (2) $$\n",
    "\n",
    "where the square root of $ùì•_*$ is a standard deviation (‚Äòuncertainty‚Äô). The coefficient $ùõΩ$ determines an exploitation-exploration trade-off. The '$+$' sign corresponds to the maximization problems, whereas the '$-$' sign is for the minimization problems. In the variational inference regime, $L=1$, and the next point is selected as $x_{next}=\\arg\\max_xŒ±(ùúá_*,ùì•_*)$.\n",
    "\n",
    "For the analytical acquisition function such as UCB, one may alternatively first derive mean and variance of the sampled predictions (```y_sampled``` in GPax code examples) and then use them to compute the acqusition function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdtH0tCPQ2de"
   },
   "source": [
    "## Install & Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86iUwKxLO7qE"
   },
   "source": [
    "Install the latest GPax package from PyPI (this is best practice, as it installs the latest, deployed and tested version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQ1rLUzqha2i",
    "outputId": "44157aab-4e21-4966-ec79-ccf85cd4bbaa"
   },
   "outputs": [],
   "source": [
    "!pip install gpax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vygoK7MTjJWB"
   },
   "source": [
    "Import needed packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # For use on Google Colab\n",
    "    import gpax\n",
    "\n",
    "except ImportError:\n",
    "    # For use locally (where you're using the local version of gpax)\n",
    "    print(\"Assuming notebook is being run locally, attempting to import local gpax module\")\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "    import gpax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KtGDc11Ehh7r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpyro\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpax.utils.enable_x64()  # enable double precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable some pretty plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('axes', labelsize=12)\n",
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Gaussian process-based Bayesian optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAejc4usmzxi"
   },
   "source": [
    "Let's define a function to be minimized and a function that emulates a noisy measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SS6wrbVHfp-N"
   },
   "outputs": [],
   "source": [
    "def func(x, y=1.2):\n",
    "    out = (\n",
    "        -20 * np.exp(-0.2 * np.sqrt(0.5 * (x**2 + y**2)))\n",
    "        - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np.pi * y)))\n",
    "        + np.e + 20\n",
    "    )\n",
    "    return out\n",
    "\n",
    "def measure(x, noise=0.1):\n",
    "    return func(x) + noise * np.random.randn(len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_lOdSM2m0WN"
   },
   "source": [
    "Next, we generate a few noisy observations of our function. We also plot the true function (\"ground truth\") to confirm the location of the minimum at $x=0$ but we are not going to use it anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "YU0DxM5UhSpd",
    "outputId": "c1366b4c-cced-4461-a899-3191b505e916"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_bounds = np.array([-2, 2])\n",
    "X = np.random.uniform(X_bounds[0], X_bounds[1], size=(8,))\n",
    "X = np.append(X, X_bounds)\n",
    "X = np.sort(X)\n",
    "y = measure(X)\n",
    "\n",
    "X_unmeasured = np.linspace(X_bounds[0], X_bounds[1], 200)\n",
    "ground_truth = measure(X_unmeasured, noise=0)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(4, 2))\n",
    "ax.set_xlabel(\"$X$\", fontsize=16)\n",
    "ax.set_ylabel(\"$y$\", fontsize=16)\n",
    "ax.scatter(X, y, marker='x', c='k', s=64, zorder=1, label=\"Observations\", alpha=1.0)\n",
    "ax.plot(X_unmeasured, ground_truth, label='Ground truth')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMqeLGCqmxrP"
   },
   "source": [
    "The Gaussian process class in GPax uses a weakly informative $LogNormal(0,1)$ prior distribution for all kernel parameters and model noise by default. If we have prior knowledge that the noise level is low, we may choose a more appropriate prior distibution for the noise, such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oY9iayqblwhT"
   },
   "outputs": [],
   "source": [
    "noise_prior = numpyro.distributions.HalfNormal(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIPjp5qDmyUi"
   },
   "source": [
    "Next we define a single step that takes measured data, trains a GP model, and uses it to compute an Upper Confidence Bound (UCB) acquisition function for deriving the next measurment point (which will be done inside the main loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uCDIAs2glWO"
   },
   "outputs": [],
   "source": [
    "def step(X_measured, y_measured, X_unmeasured):\n",
    "    \n",
    "    # Get random number generator keys for training and prediction\n",
    "    rng_key1, rng_key2 = gpax.utils.get_keys()\n",
    "    \n",
    "    # Initialize GP model\n",
    "    gp_model = gpax.ExactGP(1, kernel='RBF', noise_prior_dist=noise_prior)\n",
    "    \n",
    "    # Run HMC to obtain posterior samples for the GP model parameters\n",
    "    gp_model.fit(rng_key1, X_measured, y_measured)\n",
    "    \n",
    "    # Get predictions (we don't need this step for optimization -\n",
    "    # only for visualization purposes)\n",
    "    y_pred, y_sampled = gp_model.predict(\n",
    "        rng_key2,\n",
    "        X_unmeasured,\n",
    "        noiseless=True\n",
    "    )\n",
    "    \n",
    "    # Compute acquisition function\n",
    "    obj = gpax.acquisition.UCB(\n",
    "        rng_key2,\n",
    "        gp_model,\n",
    "        X_unmeasured,\n",
    "        beta=4,\n",
    "        maximize=False,\n",
    "        noiseless=True\n",
    "    )\n",
    "\n",
    "    return obj, (y_pred, y_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VysFg03bm1tM"
   },
   "source": [
    "Finally, we run the Bayesian optimization for 7 steps to find the minimum of the unknown (to the algorithm) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 7\n",
    "\n",
    "fig, axs = plt.subplots(num_steps, 2, figsize=(5, 8), sharex=True)\n",
    "\n",
    "axs[0, 0].set_title(\"Data & GP\")\n",
    "axs[0, 1].set_title(\"Acquisition Function\")\n",
    "\n",
    "for e in range(num_steps):\n",
    "    ax = axs[e]\n",
    "\n",
    "    print(f\"\\nStep {e+1}/{num_steps}\")\n",
    "\n",
    "    # Compute acquisition function\n",
    "    acq, (y_pred, y_sampled) = step(X, y, X_unmeasured)\n",
    "\n",
    "    # Get the next point to evaluate\n",
    "    idx = acq.argmax()\n",
    "    next_point = X_unmeasured[idx:idx+1]\n",
    "\n",
    "    # Measure the point\n",
    "    next_point_value = measure(next_point)\n",
    "\n",
    "    # Update measured data\n",
    "    X = np.append(X, X_unmeasured[idx:idx+1])\n",
    "    y = np.append(y, next_point_value)\n",
    "\n",
    "    # Plot observed points, mean prediction, and acqusition function\n",
    "    lower_b = y_pred - y_sampled.std(axis=(0,1))\n",
    "    upper_b = y_pred + y_sampled.std(axis=(0,1))\n",
    "\n",
    "    ax1 = ax[0]\n",
    "    ax2 = ax[1]\n",
    "    \n",
    "    ax1.scatter(X[:-1], y[:-1], marker='x', c='k', label=\"Observations\", s=64)\n",
    "    ax1.plot(X_unmeasured, y_pred, lw=1, c='b', label='Posterior mean')\n",
    "    ax1.fill_between(\n",
    "        X_unmeasured,\n",
    "        lower_b,\n",
    "        upper_b,\n",
    "        color='blue',\n",
    "        alpha=0.3,\n",
    "        linewidth=0,\n",
    "        label=\"Model uncertainty\", \n",
    "    )\n",
    "    \n",
    "    ax2.plot(X_unmeasured, acq, lw=2, c='orangered', label='Acquisition function')\n",
    "    ax2.scatter(\n",
    "        X_unmeasured[idx],\n",
    "        acq[idx],\n",
    "        s=30,\n",
    "        marker=\"o\",\n",
    "        color=\"black\",\n",
    "        label='Next point to measure',\n",
    "        zorder=3,\n",
    "    )\n",
    "    ax1.text(\n",
    "        0.02, 0.02, f\"{e+1}/{num_steps}\", ha=\"left\", va=\"bottom\", transform=ax1.transAxes\n",
    "    )\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v00xD07hanP8"
   },
   "source": [
    "As one can see, the algorithm quickly converged onto the true minimum. Note that in real experiments, it's practical to update the ```X_unmeasured``` at each step by removing the just measured point from it."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPMvxYQ4tezQyb1Ol39/kHB",
   "include_colab_link": true,
   "name": "gpax_GPBO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
